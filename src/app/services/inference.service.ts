
import { Injectable } from '@angular/core';
import { AutoModel, AutoTokenizer, env, FeatureExtractionPipeline, pipeline, PreTrainedModel, PreTrainedTokenizer } from '@huggingface/transformers';
import { FilesystemCache } from '../helper-class/FilesystemCache';

@Injectable({
  providedIn: 'root'
})
export class InferenceService {

  private isInitialized = false;

  tokenizer!: PreTrainedTokenizer;
  model!: PreTrainedModel;

  constructor() {
    env.allowRemoteModels = true;     // ‚úÖ Allow downloads initially
    env.allowLocalModels = false;     // ‚ùå Don't use file paths
    env.useFS = false;                // ‚ùå Disable default FS
    env.useBrowserCache = false;      // ‚ùå Disable browser cache
    env.useFSCache = false;           // ‚ùå Disable default FS cache
    env.useCustomCache = true;        // ‚úÖ Use your cache
    const cache = new FilesystemCache();
    env.customCache = cache; // Use your implementation

    if (env.backends.onnx.wasm) {
      env.backends.onnx.wasm.wasmPaths = '/assets/wasm/'
    }
  }

  public async initModel() {
    try {

      const model_id = "onnx-community/embeddinggemma-300m-ONNX";
      this.tokenizer = await AutoTokenizer.from_pretrained(model_id);
      this.model = await AutoModel.from_pretrained(model_id, {
        dtype: "q8", // Options: "fp32" | "q8" | "q4"
      });

      this.isInitialized = true;
    } catch (e) {
      console.error(e);
    }
  }

  public async generateEmbeddings(text: string, type: 'search' | 'content') {
    if (!this.isInitialized || !this.tokenizer || !this.model) {
      throw new Error('Model not initialized. Call initModel() first.');
    }

    try {
      console.log('üîÆ Generating embeddings for:', text.substring(0, 50) + '...');

      const prefixes = {
        search: "task: search result | query: ",
        content: "title: none | text: ",
      };

      const query = prefixes[type] + text;

      // Generate embeddings
      const inputs = await this.tokenizer(query, { padding: true });
      const { sentence_embedding } = await this.model(inputs);

      // Extract the embedding array
      const embeddings = Array.from(sentence_embedding.data);

      console.log('‚úÖ Generated embeddings:', embeddings.length, 'dimensions');
      return embeddings;

    } catch (error) {
      console.error('‚ùå Error generating embeddings:', error);
      throw error;
    }
  }

}
